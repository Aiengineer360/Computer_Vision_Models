{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_dnzEaLABGD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers, models\n",
        "from keras.utils import plot_model\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from skimage.transform import resize\n",
        "from keras.regularizers import l1_l2\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adamax,Nadam,Adam,RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,classification_report\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization,Input, concatenate, AveragePooling2D,GlobalAveragePooling2D,ReLU, Add\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "oo1FRteGyR8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3MJ0NATEAJiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip the dataset\n",
        "!unzip train.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImpCbRI4Aiad",
        "outputId": "ba688e01-d112-4c8d-9a58-d5f6d2a6de35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.zip\n",
            "  inflating: train_data.npz          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip the dataset\n",
        "!unzip test-11.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vqp2um9AJcj",
        "outputId": "10862afa-c7b8-4b84-9271-81fe7bdde6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  test-11.zip\n",
            "  inflating: test_data.npz           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('train_data.npz')\n",
        "test=np.load(\"test_data.npz\")\n",
        "X_loaded = data['X_train']\n",
        "y_loaded = data['y_train']\n",
        "index=test['index']\n",
        "test_images = test['X_test']"
      ],
      "metadata": {
        "id": "3FBGuWKUAIxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Images shape : \",X_loaded.shape)\n",
        "print(\"Test Images shape : \",test_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDSi2U0kDCAZ",
        "outputId": "34a78a5d-ce32-48de-fd46-ac2fc32b198f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Images shape :  (8800, 164, 164, 3)\n",
            "Test Images shape :  (2200, 164, 164, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the new size\n",
        "new_size = (128, 128, 3)"
      ],
      "metadata": {
        "id": "cTbovRvUAIu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize each image in X_loaded to new_size\n",
        "X_resized = np.array([resize(img, new_size) for img in X_loaded])"
      ],
      "metadata": {
        "id": "Z5wq2NHTAIsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize each image in test_images to new_size\n",
        "X_resized_test = np.array([resize(img, new_size) for img in test_images])"
      ],
      "metadata": {
        "id": "5ug6TcsuCq8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Images shape after resize : \",X_resized.shape)\n",
        "print(\"Test Images shape after resize : \",X_resized_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXxTFCQsAIo2",
        "outputId": "bdf4472b-e0b5-4e82-f134-be1bf6e401f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Images shape after resize :  (8800, 128, 128, 3)\n",
            "Test Images shape after resize :  (2200, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_validation, y_train, y_validation = train_test_split(X_resized, y_loaded, test_size=0.15, random_state=43)"
      ],
      "metadata": {
        "id": "LurptUENAzkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Resized {X_resized.shape[0]} images to {new_size}.\")\n",
        "print(f\"Training set: {X_train.shape}, Validation set: {X_validation.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8I_RTC2AyWE",
        "outputId": "ae580da4-7939-4c10-b112-5d8fcb73e787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized 8800 images to (128, 128, 3).\n",
            "Training set: (7480, 128, 128, 3), Validation set: (1320, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caluate mean and subtract for normalization\n",
        "mean_image = np.mean(X_train, axis=0)\n",
        "X_train -= mean_image\n",
        "X_validation -= mean_image\n",
        "X_resized_test -= mean_image"
      ],
      "metadata": {
        "id": "zIEi1nP6DW-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(y_loaded))\n",
        "print(f\"Number of classes: {num_classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIGGPUM1AyMW",
        "outputId": "2b81fd03-a0d2-43df-ddba-d504c0a0bd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_validation = keras.utils.to_categorical(y_validation, num_classes)"
      ],
      "metadata": {
        "id": "b435LJ08A6zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, strides=(1, 1), use_projection=False):\n",
        "    \"\"\" Defines a residual block in a simplified ResNet-like model \"\"\"\n",
        "    shortcut = x\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=strides, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Projection shortcut to match dimensions\n",
        "    if use_projection:\n",
        "        shortcut = layers.Conv2D(filters=filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Add shortcut to main path and pass through ReLU activation\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def create_resnet_model(input_shape=(128, 128, 3), num_classes=11):\n",
        "    \"\"\" Creates a simplified ResNet-like model with reduced parameters \"\"\"\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolutional layer\n",
        "    x = layers.Conv2D(16, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    x = residual_block(x, filters=32, strides=(2, 2), use_projection=True)\n",
        "    x = residual_block(x, filters=32, use_projection=False)\n",
        "\n",
        "    x = residual_block(x, filters=64, strides=(2, 2), use_projection=True)\n",
        "    x = residual_block(x, filters=64, use_projection=False)\n",
        "\n",
        "    # Global average pooling and dense layers\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "y9Uhqf2SA6xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the modified ResNet-like model\n",
        "model = create_resnet_model()\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7HwYnbvrxEu",
        "outputId": "7798b441-8d69-472a-8cdf-5673fc990cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 64, 64, 16)           448       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 64, 64, 16)           64        ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)     (None, 64, 64, 16)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)           4640      ['leaky_re_lu[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)           128       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 32)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 32, 32, 32)           0         ['leaky_re_lu_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 32)           9248      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 32)           128       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 32, 32, 32)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)           544       ['leaky_re_lu[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 32, 32, 32)           0         ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 32)           128       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 32, 32, 32)           0         ['dropout_2[0][0]',           \n",
            "                                                                     'batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 32)           0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)           9248      ['leaky_re_lu_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32, 32, 32)           128       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 32)           0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 32, 32, 32)           0         ['leaky_re_lu_3[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 32)           9248      ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 32)           128       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 32, 32, 32)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 32, 32, 32)           0         ['dropout_4[0][0]',           \n",
            "                                                                     'leaky_re_lu_2[0][0]']       \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 32)           0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 64)           18496     ['leaky_re_lu_4[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 64)           256       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 64)           0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 16, 16, 64)           0         ['leaky_re_lu_5[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 64)           36928     ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 16, 16, 64)           256       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 16, 16, 64)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 64)           2112      ['leaky_re_lu_4[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 16, 16, 64)           0         ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 64)           256       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 16, 16, 64)           0         ['dropout_7[0][0]',           \n",
            "                                                                     'batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 64)           0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)           36928     ['leaky_re_lu_6[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 64)           256       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 16, 16, 64)           0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 16, 16, 64)           0         ['leaky_re_lu_7[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)           36928     ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 64)           256       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 16, 16, 64)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 16, 16, 64)           0         ['dropout_9[0][0]',           \n",
            "                                                                     'leaky_re_lu_6[0][0]']       \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 16, 16, 64)           0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 64)                   0         ['leaky_re_lu_8[0][0]']       \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 64)                   4160      ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 64)                   256       ['dense[0][0]']               \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 64)                   0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 32)                   2080      ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 32)                   128       ['dense_1[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 32)                   0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 11)                   363       ['dropout_11[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 173739 (678.67 KB)\n",
            "Trainable params: 172555 (674.04 KB)\n",
            "Non-trainable params: 1184 (4.62 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='Nadam',\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_ym-7PfgA6sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "NhfxyLrqMkkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the learning rate schedule function\n",
        "import math\n",
        "def cosine_annealing(epoch, lr):\n",
        "    epochs = 100  # Total number of epochs\n",
        "    return 0.0001 + (0.1 - 0.0001) * (1 + math.cos(math.pi * epoch / epochs)) / 2"
      ],
      "metadata": {
        "id": "F895WH5ktinC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler"
      ],
      "metadata": {
        "id": "9i29PeCowFPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler\n",
        "lr_scheduler = LearningRateScheduler(cosine_annealing)"
      ],
      "metadata": {
        "id": "-oCl1k19wBE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, batch_size=64,\n",
        "          epochs=50,\n",
        "          validation_data=(X_validation, y_validation),\n",
        "          callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIbfCGQYtbHh",
        "outputId": "72616cc9-a68c-463f-c519-fd0551ea2e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "117/117 [==============================] - 32s 82ms/step - loss: 2.3791 - accuracy: 0.1520 - val_loss: 9.3046 - val_accuracy: 0.1326 - lr: 0.1000\n",
            "Epoch 2/50\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 2.2800 - accuracy: 0.1775 - val_loss: 3.6185 - val_accuracy: 0.1939 - lr: 0.1000\n",
            "Epoch 3/50\n",
            "117/117 [==============================] - 6s 52ms/step - loss: 2.2690 - accuracy: 0.1830 - val_loss: 2.9010 - val_accuracy: 0.1871 - lr: 0.0999\n",
            "Epoch 4/50\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 2.2506 - accuracy: 0.1971 - val_loss: 2.6294 - val_accuracy: 0.2159 - lr: 0.0998\n",
            "Epoch 5/50\n",
            "117/117 [==============================] - 6s 51ms/step - loss: 2.2263 - accuracy: 0.2107 - val_loss: 2.5147 - val_accuracy: 0.2356 - lr: 0.0996\n",
            "Epoch 6/50\n",
            "117/117 [==============================] - 6s 51ms/step - loss: 2.2009 - accuracy: 0.2226 - val_loss: 2.4010 - val_accuracy: 0.2136 - lr: 0.0994\n",
            "Epoch 7/50\n",
            "117/117 [==============================] - 6s 51ms/step - loss: 2.2204 - accuracy: 0.2152 - val_loss: 2.3529 - val_accuracy: 0.2144 - lr: 0.0991\n",
            "Epoch 8/50\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.1911 - accuracy: 0.2213 - val_loss: 2.4572 - val_accuracy: 0.2038 - lr: 0.0988\n",
            "Epoch 9/50\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 2.1781 - accuracy: 0.2290 - val_loss: 2.8234 - val_accuracy: 0.2121 - lr: 0.0984\n",
            "Epoch 10/50\n",
            "117/117 [==============================] - 6s 51ms/step - loss: 2.1526 - accuracy: 0.2405 - val_loss: 2.4592 - val_accuracy: 0.2152 - lr: 0.0980\n",
            "Epoch 11/50\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 2.1377 - accuracy: 0.2410 - val_loss: 2.2065 - val_accuracy: 0.2114 - lr: 0.0976\n",
            "Epoch 12/50\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 2.1263 - accuracy: 0.2453 - val_loss: 2.6811 - val_accuracy: 0.2515 - lr: 0.0970\n",
            "Epoch 13/50\n",
            "117/117 [==============================] - 6s 49ms/step - loss: 2.1159 - accuracy: 0.2536 - val_loss: 2.2908 - val_accuracy: 0.1841 - lr: 0.0965\n",
            "Epoch 14/50\n",
            "117/117 [==============================] - 6s 52ms/step - loss: 2.0960 - accuracy: 0.2611 - val_loss: 2.1185 - val_accuracy: 0.2917 - lr: 0.0959\n",
            "Epoch 15/50\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 2.0837 - accuracy: 0.2670 - val_loss: 2.1722 - val_accuracy: 0.2576 - lr: 0.0952\n",
            "Epoch 16/50\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 2.0715 - accuracy: 0.2699 - val_loss: 2.0997 - val_accuracy: 0.2856 - lr: 0.0946\n",
            "Epoch 17/50\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 2.0408 - accuracy: 0.2816 - val_loss: 2.2178 - val_accuracy: 0.2530 - lr: 0.0938\n",
            "Epoch 18/50\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 2.0432 - accuracy: 0.2872 - val_loss: 2.2368 - val_accuracy: 0.2508 - lr: 0.0930\n",
            "Epoch 19/50\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 2.0261 - accuracy: 0.2889 - val_loss: 2.2947 - val_accuracy: 0.2348 - lr: 0.0922\n",
            "Epoch 20/50\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 1.9821 - accuracy: 0.3036 - val_loss: 2.3791 - val_accuracy: 0.2273 - lr: 0.0914\n",
            "Epoch 21/50\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 1.9684 - accuracy: 0.3166 - val_loss: 2.1551 - val_accuracy: 0.2530 - lr: 0.0905\n",
            "Epoch 22/50\n",
            " 45/117 [==========>...................] - ETA: 3s - loss: 1.9265 - accuracy: 0.3340"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
        "          steps_per_epoch=len(X_train) // 64,\n",
        "          epochs=50,\n",
        "          validation_data=(X_validation, y_validation)\n",
        "          )"
      ],
      "metadata": {
        "id": "hyMe0mmByz5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model.save('/content/CNN-Model-0.keras')"
      ],
      "metadata": {
        "id": "f6KIc9PgBqej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_validation, y_validation)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUSH9mvtCBRz",
        "outputId": "7d0b32fa-0cff-4a51-de6c-bea27cfef6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 5ms/step - loss: 1.0823 - accuracy: 0.6761\n",
            "Test Loss: 1.0823\n",
            "Test Accuracy: 0.6761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the labels for the test images\n",
        "predictions = model.predict(X_resized_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vg9I0JfCKXc",
        "outputId": "a68b7fb8-d1d6-428d-efa5-413ae183368c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions from one-hot encoding to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "id": "PhNC0RYvCKUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'id': index,\n",
        "    'label': predicted_labels\n",
        "})"
      ],
      "metadata": {
        "id": "Pi04Gw1KCKSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "df.to_csv('AROOJ.csv', index=False)"
      ],
      "metadata": {
        "id": "wSMJa2u1CKPN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}